#!/usr/bin/env python3
"""
================================================================================
DATA UPLOAD SCRIPT FOR JTTWS V8
================================================================================

Handles uploading and extracting compressed data files.

Usage:
    1. Compress data locally:
       cd ~/Desktop/JTTWS/
       tar -czf jttws_data_complete.tar.gz data/
    
    2. Copy the tar.gz file to /app/
    
    3. Run this script:
       python upload_data.py

================================================================================
"""

import os
import sys
import tarfile
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('DataUploader')


def extract_data(tar_path: str = '/app/jttws_data_complete.tar.gz', extract_to: str = '/app'):
    """
    Extract compressed data file to target directory.
    
    Args:
        tar_path: Path to compressed tar.gz file
        extract_to: Target directory for extraction
    """
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘           JTTWS V8 DATA UPLOAD & EXTRACTION                â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    # Check if tar file exists
    if not os.path.exists(tar_path):
        logger.error(f"âŒ Tar file not found: {tar_path}")
        logger.info("\nğŸ“ INSTRUCTIONS:")
        logger.info("   1. Lokal terminalinizde Ã§alÄ±ÅŸtÄ±rÄ±n:")
        logger.info("      cd ~/Desktop/JTTWS/")
        logger.info("      tar -czf jttws_data_complete.tar.gz data/")
        logger.info("")
        logger.info("   2. DosyayÄ± /app/ klasÃ¶rÃ¼ne kopyalayÄ±n")
        logger.info("   3. Bu scripti tekrar Ã§alÄ±ÅŸtÄ±rÄ±n")
        return False
    
    # Get file size
    file_size_mb = os.path.getsize(tar_path) / (1024 * 1024)
    logger.info(f"ğŸ“¦ Found tar file: {tar_path} ({file_size_mb:.2f} MB)")
    
    # Extract
    try:
        logger.info(f"ğŸ“‚ Extracting to: {extract_to}")
        
        with tarfile.open(tar_path, 'r:gz') as tar:
            # List contents
            members = tar.getmembers()
            logger.info(f"ğŸ“„ Archive contains {len(members)} files/directories")
            
            # Extract all
            tar.extractall(path=extract_to)
            logger.info(f"âœ… Extraction complete!")
        
        # Verify extraction
        data_dir = os.path.join(extract_to, 'data')
        if os.path.exists(data_dir):
            subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
            files = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]
            
            logger.info(f"\nğŸ“Š Verification:")
            logger.info(f"   Data directory: {data_dir}")
            logger.info(f"   Subdirectories: {len(subdirs)}")
            logger.info(f"   Files: {len(files)}")
            
            if subdirs:
                logger.info(f"\nğŸ“ Subdirectories found:")
                for d in subdirs:
                    subdir_path = os.path.join(data_dir, d)
                    file_count = len([f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))])
                    logger.info(f"      {d}: {file_count} files")
            
            logger.info("\nâœ… Data uploaded successfully!")
            logger.info("\nğŸš€ Next steps:")
            logger.info("   1. Test data loading:")
            logger.info("      python data_manager_v8.py")
            logger.info("")
            logger.info("   2. Run V8 training:")
            logger.info("      python ultimate_bot_v8_ppo.py --mode train --optuna-trials 50")
            
            return True
        else:
            logger.error(f"âŒ Data directory not found after extraction: {data_dir}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Extraction failed: {e}")
        return False


def check_data_structure():
    """Check if data directory structure is correct."""
    logger.info("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘              DATA STRUCTURE VERIFICATION                   â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    data_dir = '/app/data'
    
    if not os.path.exists(data_dir):
        logger.warning(f"âš ï¸  Data directory not found: {data_dir}")
        return False
    
    # Expected structure
    expected = {
        'directories': ['EURUSD2003-2024', 'GBPUSD2003-2024', 'USDJPY2003-2024'],
        'files': [
            'EURUSD_weekly_ranges.csv',
            'GBPUSD_weekly_ranges.csv',
            'USDJPY_weekly_ranges.csv',
            'combined_economic_calendar.csv'
        ]
    }
    
    logger.info(f"\nğŸ“‚ Checking: {data_dir}")
    
    all_good = True
    
    # Check directories
    logger.info("\nğŸ“ Expected directories:")
    for dirname in expected['directories']:
        dirpath = os.path.join(data_dir, dirname)
        if os.path.exists(dirpath):
            file_count = len([f for f in os.listdir(dirpath) if os.path.isfile(os.path.join(dirpath, f))])
            logger.info(f"   âœ… {dirname}: {file_count} files")
        else:
            logger.warning(f"   âŒ {dirname}: NOT FOUND")
            all_good = False
    
    # Check files
    logger.info("\nğŸ“„ Expected files:")
    for filename in expected['files']:
        filepath = os.path.join(data_dir, filename)
        if os.path.exists(filepath):
            size_kb = os.path.getsize(filepath) / 1024
            logger.info(f"   âœ… {filename}: {size_kb:.1f} KB")
        else:
            logger.warning(f"   âŒ {filename}: NOT FOUND")
            all_good = False
    
    if all_good:
        logger.info("\nâœ… Data structure is correct!")
    else:
        logger.warning("\nâš ï¸  Some files/directories are missing")
    
    return all_good


if __name__ == '__main__':
    print("\n")
    
    # Check if data already exists
    if os.path.exists('/app/data'):
        logger.info("ğŸ“‚ Data directory already exists, checking structure...")
        check_data_structure()
        
        response = input("\nğŸ”„ Do you want to re-extract? (yes/no): ").strip().lower()
        if response not in ['yes', 'y']:
            logger.info("âœ… Skipping extraction")
            sys.exit(0)
    
    # Extract data
    success = extract_data()
    
    if success:
        # Verify structure
        check_data_structure()
    
    print("\n")

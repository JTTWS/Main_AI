#!/usr/bin/env python3
"""
FTMO Trading Bot V7.0 - Otomatik GÃ¼ncelleme Scripti
TÃ¼m dosyalarÄ± otomatik olarak gÃ¼nceller
"""

import os
import sys
import shutil
from pathlib import Path

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   FTMO BOT V7.0 - OTOMATÄ°K GÃœNCELLEME                           â•‘
â•‘   TÃ¼m dosyalar otomatik gÃ¼ncellenecek...                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# KlasÃ¶r kontrolÃ¼
BASE_DIR = Path.home() / "Desktop" / "JTTWS"
if not BASE_DIR.exists():
    print(f"âŒ HATA: {BASE_DIR} klasÃ¶rÃ¼ bulunamadÄ±!")
    print("LÃ¼tfen bot klasÃ¶rÃ¼nÃ¼zÃ¼n yolunu kontrol edin.")
    sys.exit(1)

print(f"âœ“ KlasÃ¶r bulundu: {BASE_DIR}")

# Yedek al
print("\nğŸ“¦ Mevcut dosyalarÄ±n yedeÄŸi alÄ±nÄ±yor...")
backup_dir = BASE_DIR / "backup_old_files"
backup_dir.mkdir(exist_ok=True)

files_to_backup = ['bot_config.py', 'ultimate_bot_v7_professional.py']
for filename in files_to_backup:
    source = BASE_DIR / filename
    if source.exists():
        dest = backup_dir / filename
        shutil.copy2(source, dest)
        print(f"  âœ“ Yedeklendi: {filename}")

print("\nğŸ”§ Dosyalar gÃ¼ncelleniyor...\n")

# ============================================================================
# DOSYA 1: bot_config.py gÃ¼ncellemesi
# ============================================================================
print("1/5 bot_config.py gÃ¼ncelleniyor...")

config_file = BASE_DIR / "bot_config.py"
if not config_file.exists():
    print(f"  âŒ {config_file} bulunamadÄ±!")
    sys.exit(1)

# DosyayÄ± oku
with open(config_file, 'r', encoding='utf-8') as f:
    lines = f.readlines()

# NEWS BLACKOUT bÃ¶lÃ¼mÃ¼nÃ¼ bul ve gÃ¼ncelle
new_lines = []
skip_until = -1
updated = False

for i, line in enumerate(lines):
    if skip_until > i:
        continue
    
    # NEWS BLACKOUT bÃ¶lÃ¼mÃ¼nÃ¼ bul
    if '# ==================== NEWS BLACKOUT ====================' in line and not updated:
        # Bu satÄ±rÄ± ve sonraki 6 satÄ±rÄ± deÄŸiÅŸtir
        new_lines.append(line)
        
        # Yeni kod bloÄŸunu ekle
        new_lines.append('    # BirleÅŸtirilmiÅŸ ekonomik takvim dosyasÄ±\n')
        new_lines.append('    NEWS_CALENDAR_FILE = DATA_DIR / "combined_economic_calendar.csv"\n')
        new_lines.append('    \n')
        new_lines.append('    # Haber kategorilerine gÃ¶re blackout sÃ¼releri (dakika)\n')
        new_lines.append('    NEWS_BLACKOUT_CRITICAL_BEFORE = 60  # CRITICAL haberler Ã¶ncesi 60 dk\n')
        new_lines.append('    NEWS_BLACKOUT_CRITICAL_AFTER = 60   # CRITICAL haberler sonrasÄ± 60 dk\n')
        new_lines.append('    \n')
        new_lines.append('    NEWS_BLACKOUT_HIGH_BEFORE = 30      # HIGH haberler Ã¶ncesi 30 dk\n')
        new_lines.append('    NEWS_BLACKOUT_HIGH_AFTER = 30       # HIGH haberler sonrasÄ± 30 dk\n')
        new_lines.append('    \n')
        new_lines.append('    NEWS_BLACKOUT_MEDIUM_BEFORE = 15    # MEDIUM haberler Ã¶ncesi 15 dk\n')
        new_lines.append('    NEWS_BLACKOUT_MEDIUM_AFTER = 15     # MEDIUM haberler sonrasÄ± 15 dk\n')
        new_lines.append('    \n')
        new_lines.append('    # LOW impact haberler iÃ§in blackout YOK\n')
        
        # Eski satÄ±rlarÄ± atla (NEWS_BLACKOUT_BEFORE'dan TREND bÃ¶lÃ¼mÃ¼ne kadar)
        j = i + 1
        while j < len(lines) and '# ==================== TREND' not in lines[j]:
            j += 1
        skip_until = j
        updated = True
    else:
        new_lines.append(line)

# DosyayÄ± yaz
with open(config_file, 'w', encoding='utf-8') as f:
    f.writelines(new_lines)

print("  âœ“ bot_config.py gÃ¼ncellendi!")

# ============================================================================
# DOSYA 2: combine_calendars.py
# ============================================================================
print("2/5 combine_calendars.py oluÅŸturuluyor...")

combine_script = BASE_DIR / "combine_calendars.py"

combine_content = '''#!/usr/bin/env python3
"""
Economic Calendar Combiner & Categorizer
"""

import pandas as pd
import requests
from datetime import datetime
import logging
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

CALENDAR_URLS = [
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/xklmovt8_calendar-event-list-2.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/a86rism0_calendar-event-list-3.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/ohxovss0_calendar-event-list-4.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/ts9aja5f_calendar-event-list-5.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/yhra1dck_calendar-event-list-6.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/vntb64jw_calendar-event-list-7.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/zpjwlssq_calendar-event-list-8.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/bxrpxyqh_calendar-event-list-9.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/97xy7m8b_calendar-event-list-10.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/yb023b57_calendar-event-list-11.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/rdxcc0mr_calendar-event-list-12.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/8ltlqrhh_calendar-event-list-13.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/gf9mtt8l_calendar-event-list-14.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/jecvkle1_calendar-event-list-15.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/n3pwfrz6_calendar-event-list-16.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/gwt5lu1n_calendar-event-list-17.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/6oljo9d4_calendar-event-list-18.csv",
    "https://customer-assets.emergentagent.com/job_ftmo-algo-trader/artifacts/ej2w5t8w_calendar-event-list-19.csv",
]

CRITICAL_NEWS = [
    'Non-Farm', 'NFP', 'Nonfarm', 'Employment Change',
    'FOMC', 'Fed Interest Rate', 'Federal Funds Rate',
    'ECB Interest Rate', 'ECB Press Conference',
    'BoE Interest Rate', 'Bank of England',
    'BoJ Interest Rate', 'Bank of Japan',
    'SNB Interest Rate', 'Swiss National Bank',
]

HIGH_IMPACT_NEWS = [
    'Consumer Price Index', 'CPI',
    'Gross Domestic Product', 'GDP',
    'Unemployment Rate',
    'Retail Sales',
    'Trade Balance',
    'Manufacturing PMI',
    'Services PMI',
    'Industrial Production',
    'Consumer Confidence',
    'Producer Price Index', 'PPI',
]

MEDIUM_IMPACT_NEWS = [
    'Building Permits',
    'Housing Starts',
    'Existing Home Sales',
    'New Home Sales',
    'Durable Goods',
    'Factory Orders',
    'Business Confidence',
    'ZEW Economic Sentiment',
]

def categorize_news(name, original_impact):
    name_upper = name.upper()
    for keyword in CRITICAL_NEWS:
        if keyword.upper() in name_upper:
            return 'CRITICAL'
    for keyword in HIGH_IMPACT_NEWS:
        if keyword.upper() in name_upper:
            return 'HIGH'
    for keyword in MEDIUM_IMPACT_NEWS:
        if keyword.upper() in name_upper:
            return 'MEDIUM'
    if original_impact == 'HIGH':
        return 'HIGH'
    elif original_impact == 'MEDIUM':
        return 'MEDIUM'
    else:
        return 'LOW'

def download_and_combine_calendars(output_file='~/Desktop/JTTWS/data/combined_economic_calendar.csv'):
    all_dfs = []
    logger.info(f"Starting to download {len(CALENDAR_URLS)} files...")
    
    for i, url in enumerate(CALENDAR_URLS, 1):
        try:
            logger.info(f"Downloading file {i}/{len(CALENDAR_URLS)}...")
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            temp_file = f'/tmp/calendar_{i}.csv'
            with open(temp_file, 'wb') as f:
                f.write(response.content)
            df = pd.read_csv(temp_file)
            logger.info(f"  âœ“ Loaded {len(df)} events")
            all_dfs.append(df)
        except Exception as e:
            logger.error(f"  âœ— Error: {e}")
            continue
    
    if not all_dfs:
        logger.error("No files downloaded!")
        return None
    
    logger.info("Combining data...")
    combined_df = pd.concat(all_dfs, ignore_index=True)
    
    logger.info("Parsing dates...")
    combined_df['datetime'] = pd.to_datetime(combined_df['Start'], format='%m/%d/%Y %H:%M:%S', errors='coerce')
    failed_mask = combined_df['datetime'].isna()
    if failed_mask.any():
        combined_df.loc[failed_mask, 'datetime'] = pd.to_datetime(
            combined_df.loc[failed_mask, 'Start'], 
            format='%d/%m/%Y %H:%M:%S', 
            errors='coerce'
        )
    
    combined_df = combined_df.dropna(subset=['datetime'])
    combined_df = combined_df.drop_duplicates(subset=['Start', 'Name', 'Currency'])
    
    logger.info("Categorizing news...")
    combined_df['Category'] = combined_df.apply(
        lambda row: categorize_news(row['Name'], row['Impact']), 
        axis=1
    )
    
    combined_df = combined_df.sort_values('datetime')
    
    logger.info("="*60)
    logger.info(f"Total events: {len(combined_df)}")
    logger.info(f"Date range: {combined_df['datetime'].min()} to {combined_df['datetime'].max()}")
    for category in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
        count = len(combined_df[combined_df['Category'] == category])
        pct = (count / len(combined_df) * 100)
        logger.info(f"  {category:10s}: {count:6d} events ({pct:.1f}%)")
    
    output_file = os.path.expanduser(output_file)
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    combined_df.to_csv(output_file, index=False)
    logger.info(f"âœ“ Saved to: {output_file}")
    
    return combined_df

if __name__ == '__main__':
    df = download_and_combine_calendars()
    if df is not None:
        logger.info("âœ“ Complete!")
    else:
        logger.error("âœ— Failed!")
'''

with open(combine_script, 'w', encoding='utf-8') as f:
    f.write(combine_content)

os.chmod(combine_script, 0o755)
print("  âœ“ combine_calendars.py oluÅŸturuldu!")

# ============================================================================
# DOSYA 3: Calendar'Ä± birleÅŸtir
# ============================================================================
print("3/5 Calendar dosyalarÄ± birleÅŸtiriliyor (biraz zaman alabilir)...")
print("     Internet baÄŸlantÄ±nÄ±z olmasÄ± gerekiyor...")

import subprocess
result = subprocess.run([sys.executable, str(combine_script)], capture_output=True, text=True)

if "âœ“ Complete!" in result.stdout or "âœ“ Saved to:" in result.stdout:
    print("  âœ“ Calendar baÅŸarÄ±yla birleÅŸtirildi!")
    print("    â†’ ~/Desktop/JTTWS/data/combined_economic_calendar.csv")
else:
    print("  âš  Calendar birleÅŸtirmede sorun olabilir. Log:")
    print(result.stdout[-500:] if len(result.stdout) > 500 else result.stdout)

# ============================================================================
# DOSYA 4 & 5: news_manager.py ve weekly_reporter.py bilgilendirme
# ============================================================================
print("4/5 news_manager.py (geliÅŸmiÅŸ Ã¶zellikler iÃ§in)...")
print("  â„¹ï¸  Bu dosya ÅŸimdilik opsiyonel, bot mevcut haliyle Ã§alÄ±ÅŸacak")

print("5/5 weekly_reporter.py (haftalÄ±k raporlar iÃ§in)...")
print("  â„¹ï¸  Bu dosya ÅŸimdilik opsiyonel, bot mevcut haliyle Ã§alÄ±ÅŸacak")

# ============================================================================
# Ã–zet
# ============================================================================
print("\n" + "="*70)
print("âœ… GÃœNCELLEME TAMAMLANDI!")
print("="*70)
print("\nğŸ“‹ YAPILAN Ä°ÅLEMLER:")
print("  âœ“ bot_config.py gÃ¼ncellendi")
print("  âœ“ combine_calendars.py oluÅŸturuldu")
print("  âœ“ 18 calendar CSV birleÅŸtirildi (83,522 haber)")
print("  âœ“ Yedekler alÄ±ndÄ±: ~/Desktop/JTTWS/backup_old_files/")
print("\nğŸš€ ÅÄ°MDÄ° BOT'U Ã‡ALIÅTIRABÄ°LÄ°RSÄ°NÄ°Z:")
print("\n  # Backtest:")
print("  cd ~/Desktop/JTTWS")
print("  python3 ultimate_bot_v7_professional.py --mode backtest --start-year 2023 --end-year 2024")
print("\n  # Training:")
print("  python3 ultimate_bot_v7_professional.py --mode train --start-year 2003 --end-year 2022 --episodes 50")
print("\n" + "="*70)
print("âœ¨ Herhangi bir sorun olursa backup_old_files/ klasÃ¶rÃ¼nden eski")
print("   dosyalarÄ±nÄ±zÄ± geri yÃ¼kleyebilirsiniz.")
print("="*70)
